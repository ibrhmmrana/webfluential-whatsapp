-- Knowledge base for RAG: store text chunks and embeddings for semantic search
create extension if not exists vector;

create table if not exists knowledge_base (
  id bigint generated by default as identity primary key,
  source text not null,
  content text not null,
  embedding vector(1536) not null,
  metadata jsonb,
  created_at timestamptz not null default now()
);

create index if not exists idx_knowledge_base_embedding on knowledge_base
  using hnsw (embedding vector_cosine_ops)
  with (m = 16, ef_construction = 64);

create index if not exists idx_knowledge_base_source on knowledge_base (source);

comment on table knowledge_base is 'Chunks of text with embeddings for RAG. source e.g. FAQ, content = chunk text, embedding from OpenAI text-embedding-3-small.';

-- RPC: return top match_count rows by cosine similarity to query_embedding
create or replace function match_knowledge(
  query_embedding vector(1536),
  match_count int default 5
)
returns table (
  id bigint,
  source text,
  content text,
  similarity float
)
language sql stable
as $$
  select
    knowledge_base.id,
    knowledge_base.source,
    knowledge_base.content,
    1 - (knowledge_base.embedding <=> query_embedding) as similarity
  from knowledge_base
  order by knowledge_base.embedding <=> query_embedding
  limit match_count;
$$;
